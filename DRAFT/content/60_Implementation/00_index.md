# Implementation

==DRAFT==

The **Implementation** pillar ensures that secure, ethical, and resilient practices are embedded throughout the AI system development lifecycle.

Unlike traditional software, AI systems introduce additional complexities such as dynamic model behavior, data-driven vulnerabilities, and evolving threat landscapes. These systems often make autonomous decisions based on probabilistic outputs, increasing the potential for unpredictable or unintended behavior. Therefore, organizations must adopt tailored implementation practices that address these unique risks at every phaseâ€”from data handling and model training to deployment and post-deployment management. Furthermore, the integration of external AI services and pre-trained models demands heightened scrutiny regarding supply chain integrity and continuous performance monitoring.

The Implementation pillar is organized into three interconnected practices that reflect the critical stages where AI systems must be safeguarded:

1. **Secure Build**: Integrating secure development practices, data hygiene, supply chain validation, and responsible AI principles during model creation, selection, and integration. This includes ensuring that input/output behaviors are well understood and that components are sourced, configured, and validated securely.
2. **Secure Deployment**: Protecting AI models and associated data throughout the deployment process by ensuring operational resilience, maintaining confidentiality, safeguarding integrity, and monitoring system behavior under live conditions. This phase also emphasizes the need for governance, rollback planning, and compliance verification.
3. **Defect Management**: Establishing ongoing processes for the systematic identification, prioritization, and mitigation of vulnerabilities, performance issues, and ethical risks within AI systems. Defect management is crucial for maintaining long-term trustworthiness and ensuring that AI behaviors align with organizational values and regulatory expectations.

By adopting these practices, organizations can proactively mitigate risks related to model misuse, bias, adversarial manipulation, and data leakage. In doing so, they not only achieve compliance with evolving legal and ethical standards but also build durable trust with users, partners, and regulators across diverse application domains.

> **Open Points**: Where do we put things from the GenAI Top 10? What about Human-in-the-Loop?   