## Conducting AIMA Assessment

Assessing an organization using AIMA is very similar to the SAMM assessment methodology, but focused on AI systems and practices. By measuring the organization against AIMA’s defined Governance practices, one can create an overall picture of the **AI governance and assurance activities** in place. This helps in understanding the current breadth of responsible AI measures and in planning a roadmap for improvement. As with SAMM, there are two recommended styles for conducting an AIMA assessment:

* **Lightweight Assessment:** Use the AIMA assessment worksheets for each practice (e.g. Strategy & Metrics, Policy & Compliance, Education & Awareness for the Governance Businee Function) to answer a series of yes/no questions. Each practice’s worksheet covers key activities or criteria at each maturity level. Based on the responses, assign a provisional maturity level score for each practice. This lightweight approach is usually sufficient for an organization looking to quickly map its existing AI governance efforts onto the AIMA model and get a high-level view of where they stand. For example, a team might answer the questions for **Strategy & Metrics** and determine that they meet all Level 1 criteria and some Level 2 – giving them an initial score of 1+ (as explained below). The lightweight assessment is quick and can often be done via interviews and document reviews, without deep verification.

* **Detailed Assessment:** This goes a step further by incorporating verification and evidence gathering after the initial questionnaire. Once the worksheets are completed, the assessors perform additional **audit** activities to confirm that the prescribed AIMA activities at each level are truly in place (not just “paper compliance”). For instance, if a Level 2 activity requires *regular AI model risk assessments*, a detailed assessment might involve reviewing a sample of project documents or interviewing staff to ensure those risk assessments are happening with the intended quality. Moreover, AIMA (like SAMM) provides **Success Metrics** for each practice, so a detailed assessment will also involve collecting data on those metrics to see if performance meets expectations. In short, the detailed approach validates the answers given in the lightweight step and requires evidence (e.g. policy documents, training records, model evaluation reports), giving a higher confidence in the accuracy of the maturity rating.

**Scoring:** Scoring in AIMA follows the SAMM scoring model. After answering the yes/no questions in a practice’s worksheet, you determine the maturity level achieved for that practice. In general, if an organization answers “Yes” to all questions up to a certain level’s marker, it achieves that level. For example, if all Level 1 criteria for **Policy & Compliance** are met, the organization is at least Level 1 in that practice. If it also meets some (but not all) Level 2 criteria, we denote that as **“Level 1+”**. The “+” indicates partial progress toward the next level. This is important because organizations don’t always neatly fit into exact levels – they might be between levels, doing some advanced activities without having fully completed all prior maturity criteria. The plus designation captures that extra assurance in place beyond the base level obtained.

Scores for each practice can thus be **0, 1, 2, 3** or a **“+” variant** (e.g. 1+, 2+, 3+). A score of 0 means no appreciable activity in that area yet. A 3 (or 3+) is the highest, indicating the organization performs all defined activities (and possibly even beyond what AIMA defines) for that practice. Once each practice is scored, the organization can visualize its overall Governance maturity (often using a radar chart or scorecard) and identify which areas to target for improvement.

It’s also wise to consider the **scope** of the assessment – e.g. whether you are assessing the entire organization’s AI program or just one business unit or project. If the scope is narrower, some activities might be handled outside your scope (for example, a centralized AI governance function at corporate level), and the assessment should note those cases rather than simply marking “No” (similar to SAMM’s guidance on not prematurely labeling things *Not Applicable*). In any case, conducting an AIMA assessment – whether lightweight or detailed – enables a structured evaluation of AI maturity and a fact-based discussion on how to advance responsible AI governance in alignment with business goals.

